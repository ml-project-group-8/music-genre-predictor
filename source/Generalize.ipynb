{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.multiclass import OneVsOneClassifier\n",
    "# Preprocessing and visualization\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Metric functions\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors    import KNeighborsClassifier\n",
    "from sklearn.dummy        import DummyClassifier\n",
    "from sklearn.tree         import DecisionTreeClassifier\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ignore warnings if they happen, we don't care (that much)\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# Cross-validation takes a minute, so we will save these models\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df     = pd.read_csv(\"data/lyrical_genius.csv\")\n",
    "\n",
    "# Remove pop songs, they are all over the place and hurt classification\n",
    "df = df[(df[\"Genre\"] != \"pop\")]\n",
    "\n",
    "# Remove some irrelevant columns\n",
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "df = df.drop(columns=\"Unnamed: 0.1\")\n",
    "\n",
    "# We go ahead and remove ALL duplicates\n",
    "df = df.drop_duplicates(subset=[\"Name\",\"Artist\"],keep=False)\n",
    "\n",
    "# Give each genre a new cool color\n",
    "genres = df[\"Genre\"].unique()\n",
    "unique_colors = [\n",
    "    '#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080'\n",
    "]\n",
    "colors = {}\n",
    "i = 0\n",
    "for genre in genres:\n",
    "    colors[genre] = unique_colors[i]\n",
    "    i+=1\n",
    "\n",
    "\n",
    "# Upsample the amount of occurances of values that don't appear very often\n",
    "# df = df.append(df[((df[\"Genre\"] != \"country\") & (df[\"Genre\"] != \"edm_dance\"))])\n",
    "# extras    = df.copy()\n",
    "# counts    = df[\"Genre\"].value_counts()\n",
    "# max_count = max(df[\"Genre\"].value_counts())\n",
    "# for genre in genres:\n",
    "#     needed = max_count - counts[genre]\n",
    "#     extras = extras.append(df[df[\"Genre\"]==genre].sample(n=needed,replace=True))\n",
    "# df = extras\n",
    "counts    = df[\"Genre\"].value_counts()\n",
    "colors_list = [colors[genre] for genre in genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into data frames of the right type\n",
    "x_cols    = [\"Is_Exp\",\"Danceability\",\"Energy\",\"Key\",\"Loudness\",\"Mode\",\"Speechiness\",\"Acousticness\",\"Instrumentalness\",\"Liveness\",\"Valence\",\"Tempo\",\"Time_Signature\"]\n",
    "y_cols    = [\"Genre\"]\n",
    "meta_cols = [\"Id\",\"Popularity\",\"Name\",\"Artist\"]\n",
    "\n",
    "X,y,meta = df[x_cols],df[y_cols].iloc[:,0],df[meta_cols]\n",
    "\n",
    "# Split \n",
    "X_trainP, X_testP, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=1234, stratify=y)\n",
    "\n",
    "extras    = X_trainP.copy()\n",
    "counts    = y_train.value_counts()\n",
    "min_count = min(counts)\n",
    "extra_y   = pd.Series()\n",
    "for genre in genres:\n",
    "    for i in range(min_count):\n",
    "        extra_y = extra_y.append(pd.Series([genre]))\n",
    "    extras = extras.append(X_trainP[y_train==genre].sample(n=needed,replace=False))\n",
    "X_trainP = extras\n",
    "y_train = y_train.append(extra_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13398, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data and fit run 2D PCA on it\n",
    "scaler   = StandardScaler()\n",
    "scaler.fit(X_trainP)\n",
    "X_train = scaler.transform(X_trainP)\n",
    "X_test  = scaler.transform(X_testP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler,\"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "           random_state=1234, refit=True, scoring=None, solver='lbfgs',\n",
      "           tol=0.0001, verbose=0)\n",
      "Training Accuracy: 0.7151067323481116\n",
      "Testing  Accuracy: 0.8060230292294066\n",
      "['rnb' 'hiphop' 'country' 'classical' 'edm_dance' 'rock']\n",
      "[[ 33  16   8   0   4   4]\n",
      " [ 18  57   3   0   3   0]\n",
      " [ 18   1 128   2   2  29]\n",
      " [  2   1  16 528   9   3]\n",
      " [ 11   6  16   1 114  21]\n",
      " [  3   1  11   0  10  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       0.99      0.94      0.97       559\n",
      "     country       0.70      0.71      0.71       180\n",
      "   edm_dance       0.80      0.67      0.73       169\n",
      "      hiphop       0.70      0.70      0.70        81\n",
      "         rnb       0.39      0.51      0.44        65\n",
      "        rock       0.47      0.67      0.55        75\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1129\n",
      "   macro avg       0.68      0.70      0.68      1129\n",
      "weighted avg       0.83      0.81      0.81      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=1234, multi_class=\"multinomial\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "joblib.dump(clf, \"logistic.pkl\")\n",
    "y_pred = clf.predict(X_test)\n",
    "training = clf.score(X_train, y_train)\n",
    "testing  = clf.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(genres)\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = X_test[(y_test != y_pred)]\n",
    "ymiss  = y_test[(y_test != y_pred)]\n",
    "missP  = clf.predict_proba(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxclass = missP.argmax(axis=1)\n",
    "maxprob  = missP.max(axis=1)\n",
    "biggest  = maxprob.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edm_dance\n",
      "0.9811733143375763\n",
      "['classical']\n"
     ]
    }
   ],
   "source": [
    "print(ymiss.iloc[biggest]) # Actual\n",
    "print(max(max(clf.predict_proba(missed[biggest].reshape(1,-1)))))\n",
    "print(clf.predict(missed[biggest].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000e+00,  4.02000e-01,  2.23000e-01,  0.00000e+00,\n",
       "       -1.75950e+01,  0.00000e+00,  3.56000e-02,  9.89000e-01,\n",
       "        9.63000e-01,  1.20000e-01,  3.85000e-02,  1.27059e+02,\n",
       "        3.00000e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(missed[biggest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical\n",
      "(-0.04055103473933157, 'Liveness')\n",
      "(-0.05562804199168221, 'Tempo')\n",
      "(-0.09802944762858233, 'Mode')\n",
      "(0.19993213862397077, 'Speechiness')\n",
      "(-0.20023035545441323, 'Key')\n",
      "(-0.26327756993277496, 'Time_Signature')\n",
      "(0.28587503489884003, 'Valence')\n",
      "(0.3953124608225859, 'Energy')\n",
      "(-0.5538082699210936, 'Is_Exp')\n",
      "(1.0933808491101127, 'Acousticness')\n",
      "(1.4590262442458395, 'Instrumentalness')\n",
      "(-1.5247400605918369, 'Danceability')\n",
      "(-2.5265677186344293, 'Loudness')\n",
      "country\n",
      "(-0.002337469473319377, 'Liveness')\n",
      "(-0.09048753748236983, 'Time_Signature')\n",
      "(0.12304922400643863, 'Tempo')\n",
      "(0.1324299540450898, 'Key')\n",
      "(0.23162379173869044, 'Acousticness')\n",
      "(0.38532165177046096, 'Loudness')\n",
      "(-0.41925794665656974, 'Instrumentalness')\n",
      "(-0.6417256793059505, 'Danceability')\n",
      "(-0.6439301224052372, 'Energy')\n",
      "(0.6793522575646934, 'Mode')\n",
      "(0.893840685133813, 'Valence')\n",
      "(-1.0374038284316522, 'Speechiness')\n",
      "(-1.1932318050404125, 'Is_Exp')\n",
      "edm_dance\n",
      "(-0.0256052301072368, 'Speechiness')\n",
      "(-0.04590077993697691, 'Key')\n",
      "(0.05918952086080993, 'Time_Signature')\n",
      "(0.07092721943259708, 'Acousticness')\n",
      "(0.11479717049194542, 'Liveness')\n",
      "(-0.19526298507687165, 'Mode')\n",
      "(0.2624904757973639, 'Tempo')\n",
      "(-0.3782661256415102, 'Is_Exp')\n",
      "(0.8383586275036614, 'Energy')\n",
      "(0.906316220745579, 'Loudness')\n",
      "(0.9292537639359426, 'Danceability')\n",
      "(-1.040600869807904, 'Valence')\n",
      "(1.551227177450596, 'Instrumentalness')\n",
      "hiphop\n",
      "(0.05970275760708325, 'Key')\n",
      "(-0.08658627752134819, 'Liveness')\n",
      "(0.1771603193027693, 'Time_Signature')\n",
      "(0.19356279307078014, 'Loudness')\n",
      "(0.25972524565657396, 'Energy')\n",
      "(-0.27292389222915736, 'Valence')\n",
      "(-0.3170107480471687, 'Mode')\n",
      "(-0.3310356811043825, 'Tempo')\n",
      "(-0.36784832581677623, 'Acousticness')\n",
      "(1.3397115998837155, 'Speechiness')\n",
      "(1.3695368295502819, 'Is_Exp')\n",
      "(2.0705839477982293, 'Danceability')\n",
      "(-2.752786862821246, 'Instrumentalness')\n",
      "rnb\n",
      "(-0.010677751038051063, 'Key')\n",
      "(-0.01175963862421315, 'Valence')\n",
      "(-0.06872559375855261, 'Liveness')\n",
      "(0.13532251614383772, 'Time_Signature')\n",
      "(-0.16207522581527753, 'Mode')\n",
      "(-0.17501001329997362, 'Tempo')\n",
      "(0.2543246408742913, 'Instrumentalness')\n",
      "(-0.34658824176230707, 'Acousticness')\n",
      "(0.4671438340867011, 'Speechiness')\n",
      "(0.6187736498526603, 'Danceability')\n",
      "(0.6270913936917547, 'Is_Exp')\n",
      "(0.8811802711161865, 'Loudness')\n",
      "(-1.2555319919140118, 'Energy')\n",
      "rock\n",
      "(-0.017907248892257692, 'Time_Signature')\n",
      "(0.06467617477725238, 'Key')\n",
      "(0.08340320500059814, 'Liveness')\n",
      "(-0.09253325309289015, 'Instrumentalness')\n",
      "(0.09302614900320211, 'Mode')\n",
      "(0.1286779773609945, 'Is_Exp')\n",
      "(0.14556868062864703, 'Valence')\n",
      "(0.16018678193139127, 'Loudness')\n",
      "(0.17613403659223, 'Tempo')\n",
      "(0.4060657803364077, 'Energy')\n",
      "(-0.6814952927023191, 'Acousticness')\n",
      "(-0.943778514055478, 'Speechiness')\n",
      "(-1.4521456216890782, 'Danceability')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf.classes_)):\n",
    "    print(clf.classes_[i])\n",
    "    todos      = [(clf.coef_[i][j],list(X)[j]) for j in range(len(list(X)))]\n",
    "    todos.sort(key=lambda x: abs(x[0]))\n",
    "    for i in range(len(todos)):\n",
    "        print(todos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_classifier(X, y, t_clf, params,scores=[\"accuracy\"]) :\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameters of a Decision Tree classifier,\n",
    "    calculating the k-fold CV performance for each setting and metric,\n",
    "    then selects the hyperparameters that maximize the average performance for each metric.\n",
    "    \"\"\"\n",
    "    best_parms = []\n",
    "    \n",
    "    for score in scores:\n",
    "        base_clf = clone(t_clf)\n",
    "        print(\"Scoring for {}\".format(score))\n",
    "        clf   = GridSearchCV(base_clf, params, cv=5,scoring=score)\n",
    "        \n",
    "        clf.fit(X,y)\n",
    "        print(\"Done fitting\")\n",
    "        \n",
    "        mts   = clf.cv_results_[\"mean_test_score\"]\n",
    "        parms = clf.cv_results_[\"params\"]\n",
    "        \n",
    "        for mt, parm in zip(mts,parms):\n",
    "            print(\"Score: {:.4f}; Parameters {}\".format(mt, parm))\n",
    "        \n",
    "        best_parms.append(clf.best_estimator_)\n",
    "    return best_parms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "           random_state=1234, refit=True, scoring=None, solver='lbfgs',\n",
      "           tol=0.0001, verbose=0)\n",
      "Training Accuracy: 1.0\n",
      "Testing  Accuracy: 0.7723649247121346\n",
      "[[ 18  18  15   1   9   4]\n",
      " [ 17  49   1   0  12   2]\n",
      " [ 12   1 130  11  12  14]\n",
      " [  3   1  10 533   9   3]\n",
      " [  8   5  22   4 119  11]\n",
      " [  7   3  25   3  14  23]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       0.97      0.95      0.96       559\n",
      "     country       0.64      0.72      0.68       180\n",
      "   edm_dance       0.68      0.70      0.69       169\n",
      "      hiphop       0.64      0.60      0.62        81\n",
      "         rnb       0.28      0.28      0.28        65\n",
      "        rock       0.40      0.31      0.35        75\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1129\n",
      "   macro avg       0.60      0.59      0.60      1129\n",
      "weighted avg       0.77      0.77      0.77      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = [\"uniform\"]\n",
    "params  = {\n",
    "    \"n_neighbors\": range(5,22,2)\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "# clf = best_classifier(X_train,y_train,knn,params)[0]\n",
    "\n",
    "print(clf)\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf, \"knn.pkl\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "training = clf.score(X_train, y_train)\n",
    "testing  = clf.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Training Accuracy: 0.822585460516495\n",
      "Testing  Accuracy: 0.7821080602302923\n",
      "[[ 35  14   9   0   4   3]\n",
      " [ 25  49   4   0   3   0]\n",
      " [ 28   2 118   5   3  24]\n",
      " [  7   3   6 532   4   7]\n",
      " [ 16   5  13   1 106  28]\n",
      " [  8   2  11   1  10  43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       0.99      0.95      0.97       559\n",
      "     country       0.73      0.66      0.69       180\n",
      "   edm_dance       0.82      0.63      0.71       169\n",
      "      hiphop       0.65      0.60      0.63        81\n",
      "         rnb       0.29      0.54      0.38        65\n",
      "        rock       0.41      0.57      0.48        75\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1129\n",
      "   macro avg       0.65      0.66      0.64      1129\n",
      "weighted avg       0.82      0.78      0.79      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": range(5,12),\n",
    "    \"min_samples_leaf\": range(1,10),\n",
    "    \"criterion\": [\"entropy\",\"gini\"]\n",
    "}\n",
    "t = DecisionTreeClassifier()\n",
    "\n",
    "# DTree = best_classifier(X_train, y_train, t, params, scores=[\"accuracy\"])[0]\n",
    "\n",
    "\n",
    "DTree = DecisionTreeClassifier(max_depth=9, min_samples_leaf=4, criterion=\"gini\")\n",
    "DTree.fit(X_train, y_train)\n",
    "print(DTree)\n",
    "joblib.dump(DTree, \"dtree.pkl\")\n",
    "\n",
    "# predict genres of test data\n",
    "accuracy = DTree.score(X_test,y_test)\n",
    "y_pred = DTree.predict(X_test)\n",
    "training = DTree.score(X_train, y_train)\n",
    "testing  = DTree.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = DTree.feature_importances_\n",
    "d_feats      = list(X)\n",
    "todos      = [(importance[i],d_feats[i]) for i in range(len(d_feats))]\n",
    "todos.sort(key=lambda x: x[0],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2555225603233197, 'Loudness'),\n",
       " (0.12869858397543027, 'Speechiness'),\n",
       " (0.11931341838824691, 'Instrumentalness'),\n",
       " (0.11616843759700468, 'Is_Exp'),\n",
       " (0.10990970360365304, 'Danceability'),\n",
       " (0.09665024570718239, 'Acousticness'),\n",
       " (0.047585882456287656, 'Energy'),\n",
       " (0.04054549736718052, 'Tempo'),\n",
       " (0.033004374252821024, 'Valence'),\n",
       " (0.02234237504738629, 'Liveness'),\n",
       " (0.020973164048562525, 'Mode'),\n",
       " (0.009285757232924822, 'Key'),\n",
       " (0.0, 'Time_Signature')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for x in todos:\n",
    "    total += x[0]\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(todos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier accuracy is\n",
      "0.1629760850310009\n"
     ]
    }
   ],
   "source": [
    "# compare to stratified dummy classifier\n",
    "dummy = DummyClassifier(strategy='stratified')\n",
    "\n",
    "\n",
    "\n",
    "dummy.fit(X_train,y_train)\n",
    "\n",
    "joblib.dump(dummy, \"dummy.pkl\")\n",
    "dummy_accuracy = dummy.score(X_test,y_test)\n",
    "print( \"Dummy classifier accuracy is\" )\n",
    "print(dummy_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_performance(clf, X, y, kf, metrics=[\"accuracy\"]) :\n",
    "    \"\"\"\n",
    "    Splits the data, X and y, into k-folds and runs k-fold cross-validation.\n",
    "    Trains classifier on k-1 folds and tests on the remaining fold.\n",
    "    Calculates the k-fold cross-validation accuracy for classifier\n",
    "    by averaging the performance across folds.\n",
    "    \n",
    "    Adapted for HW6\n",
    "    \"\"\"\n",
    "    y=np.array(y.tolist())\n",
    "    k = kf.get_n_splits(X, y)\n",
    "    m = len(metrics)\n",
    "    scores = np.empty((m, k))\n",
    "    m=0\n",
    "    for k, (train, test) in enumerate(kf.split(X, y)) :\n",
    "        X_train = X[train]\n",
    "        X_test = X[test]\n",
    "        y_train = y[train]\n",
    "        y_test = y[test]\n",
    "        clf.fit(X_train, y_train)\n",
    "        # use Decision_tree_classifier.predict to make predictions\n",
    "        y_pred = clf.predict(X_test)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        scores[m,k] = score\n",
    "            \n",
    "    return scores.mean(axis=1) # average across columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_params(X, y, kf, metrics=[\"accuracy\"]) :\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameters of a Decision Tree classifier,\n",
    "    calculating the k-fold CV performance for each setting and metric,\n",
    "    then selects the hyperparameters that maximize the average performance for each metric.\n",
    "    \n",
    "    Adapted from HW6\n",
    "    \"\"\"\n",
    "\n",
    "    # part 4b: for each metric, select optimal hyperparameters using cross-validation\n",
    "    \n",
    "    # create grid of hyperparameters\n",
    "    # hint: use a small 2x2 grid of hyperparameters for debugging\n",
    "    depth_range = range(5,21)\n",
    "    min_samples_range = range(1,15)\n",
    "    scores = np.empty((len(metrics), len(depth_range), len(min_samples_range)))\n",
    "\n",
    "    # compute CV scores using cv_performance(...)\n",
    "    for depth_ind, max_depth in enumerate(depth_range):\n",
    "        for samples_ind, min_samples in enumerate(min_samples_range):\n",
    "            clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=max_depth, min_samples_leaf=min_samples) \n",
    "            # compute CV scores using cv_performance(...)\n",
    "            score = cv_performance(clf, X, y, kf, metrics)\n",
    "            scores[:,depth_ind,samples_ind] = score\n",
    "    \n",
    "    # get best hyperparameters\n",
    "    best_params = []\n",
    "    for met_ind, metric in enumerate(scores):\n",
    "        print (metrics[met_ind])\n",
    "        print (\"maximum score is\", metric.max())\n",
    "        depth_ind, samples_ind = np.unravel_index(metric.argmax(), metric.shape)\n",
    "        params = (depth_range[depth_ind], min_samples_range[samples_ind])\n",
    "        print( \"max_depth, min_samples=\", params)\n",
    "        best_params.append(params)\n",
    "    \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2ae98e672ed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# optimize parameters with cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mopt_max_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_min_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# train classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-f85fe9fcc34a>\u001b[0m in \u001b[0;36mselect_params\u001b[0;34m(X, y, kf, metrics)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdepth_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msamples_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_samples_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0;31m# compute CV scores using cv_performance(...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# optimize parameters with cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)\n",
    "opt_max_depth, opt_min_samples = select_params(X_train, y_train, skf)[0]\n",
    "\n",
    "# train classifier\n",
    "DTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=opt_max_depth, min_samples_leaf=opt_min_samples)\n",
    "DTree.fit(X_train,y_train)\n",
    "\n",
    "# predict genres of test data\n",
    "accuracy = DTree.score(X_test,y_test)\n",
    "\n",
    "print(\"Test accuracy of the DTree is\")\n",
    "print(accuracy)\n",
    "print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
