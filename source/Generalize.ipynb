{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.multiclass import OneVsOneClassifier\n",
    "# Preprocessing and visualization\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Metric functions\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors    import KNeighborsClassifier\n",
    "from sklearn.dummy        import DummyClassifier\n",
    "from sklearn.tree         import DecisionTreeClassifier\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ignore warnings if they happen, we don't care (that much)\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# Cross-validation takes a minute, so we will save these models\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Id</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Is_Exp</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Key</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Time_Signature</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rnb</td>\n",
       "      <td>3ibKnFDaa3GhpPGlOUj7ff</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>Let Me Love You</td>\n",
       "      <td>Mario</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.578</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.970</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.556</td>\n",
       "      <td>94.514</td>\n",
       "      <td>4</td>\n",
       "      <td>Mmmm Mmmmm Yeah Mmmmm Yeah, yeah, yeah Mmmm Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rnb</td>\n",
       "      <td>2aIdVb8v9KTpEZnftkz2mD</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>Buy U a Drank (Shawty Snappin')</td>\n",
       "      <td>T-Pain</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.550</td>\n",
       "      <td>1</td>\n",
       "      <td>-8.137</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2620</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.594</td>\n",
       "      <td>80.001</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rnb</td>\n",
       "      <td>7DFnq8FYhHMCylykf6ZCxA</td>\n",
       "      <td>69</td>\n",
       "      <td>False</td>\n",
       "      <td>Yo (Excuse Me Miss)</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.612</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.847</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2720</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.570</td>\n",
       "      <td>86.768</td>\n",
       "      <td>4</td>\n",
       "      <td>Let’s get ONE. THING. STRAIGHT! Certain shit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rnb</td>\n",
       "      <td>39YovPslPCXbFYhlYjsZ2Y</td>\n",
       "      <td>67</td>\n",
       "      <td>False</td>\n",
       "      <td>Don't Mess With My Man</td>\n",
       "      <td>Nivea</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.730</td>\n",
       "      <td>11</td>\n",
       "      <td>-4.369</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.885</td>\n",
       "      <td>99.925</td>\n",
       "      <td>4</td>\n",
       "      <td>] Uh, I like it baby, uh  Uh, one time for the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rnb</td>\n",
       "      <td>3LmvfNUQtglbTrydsdIqFU</td>\n",
       "      <td>72</td>\n",
       "      <td>False</td>\n",
       "      <td>We Belong Together</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.992</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.778</td>\n",
       "      <td>139.975</td>\n",
       "      <td>4</td>\n",
       "      <td>Ooh, oh oh Sweet love, yeah   I didn't mean i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Genre                      Id  Popularity  Is_Exp  \\\n",
       "0   rnb  3ibKnFDaa3GhpPGlOUj7ff          80   False   \n",
       "1   rnb  2aIdVb8v9KTpEZnftkz2mD          78   False   \n",
       "2   rnb  7DFnq8FYhHMCylykf6ZCxA          69   False   \n",
       "3   rnb  39YovPslPCXbFYhlYjsZ2Y          67   False   \n",
       "4   rnb  3LmvfNUQtglbTrydsdIqFU          72   False   \n",
       "\n",
       "                              Name        Artist  Danceability  Energy  Key  \\\n",
       "0                  Let Me Love You         Mario         0.656   0.578    7   \n",
       "1  Buy U a Drank (Shawty Snappin')        T-Pain         0.451   0.550    1   \n",
       "2              Yo (Excuse Me Miss)   Chris Brown         0.536   0.612    4   \n",
       "3           Don't Mess With My Man         Nivea         0.879   0.730   11   \n",
       "4               We Belong Together  Mariah Carey         0.838   0.469    0   \n",
       "\n",
       "   Loudness  Mode  Speechiness  Acousticness  Instrumentalness  Liveness  \\\n",
       "0    -8.970     0       0.0922        0.2350               0.0    0.1180   \n",
       "1    -8.137     1       0.2620        0.0108               0.0    0.0737   \n",
       "2    -5.847     1       0.2720        0.1190               0.0    0.2090   \n",
       "3    -4.369     0       0.1640        0.1140               0.0    0.2410   \n",
       "4    -7.992     1       0.0835        0.0358               0.0    0.0928   \n",
       "\n",
       "   Valence    Tempo  Time_Signature  \\\n",
       "0    0.556   94.514               4   \n",
       "1    0.594   80.001               4   \n",
       "2    0.570   86.768               4   \n",
       "3    0.885   99.925               4   \n",
       "4    0.778  139.975               4   \n",
       "\n",
       "                                              Lyrics  \n",
       "0   Mmmm Mmmmm Yeah Mmmmm Yeah, yeah, yeah Mmmm Y...  \n",
       "1                                               None  \n",
       "2   Let’s get ONE. THING. STRAIGHT! Certain shit ...  \n",
       "3  ] Uh, I like it baby, uh  Uh, one time for the...  \n",
       "4   Ooh, oh oh Sweet love, yeah   I didn't mean i...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df     = pd.read_csv(\"data/lyrical_genius.csv\")\n",
    "\n",
    "# Remove pop songs, they are all over the place and hurt classification\n",
    "df = df[(df[\"Genre\"] != \"pop\")]\n",
    "\n",
    "# Remove some irrelevant columns\n",
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "df = df.drop(columns=\"Unnamed: 0.1\")\n",
    "\n",
    "# We go ahead and remove ALL duplicates\n",
    "df = df.drop_duplicates(subset=[\"Name\",\"Artist\"],keep=False)\n",
    "\n",
    "# Give each genre a new cool color\n",
    "genres = df[\"Genre\"].unique()\n",
    "unique_colors = [\n",
    "    '#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080'\n",
    "]\n",
    "colors = {}\n",
    "i = 0\n",
    "for genre in genres:\n",
    "    colors[genre] = unique_colors[i]\n",
    "    i+=1\n",
    "    \n",
    "# Upsample the amount of occurances of values that don't appear very often\n",
    "# df = df.append(df[((df[\"Genre\"] != \"country\") & (df[\"Genre\"] != \"edm_dance\"))])\n",
    "extras    = df.copy()\n",
    "counts    = df[\"Genre\"].value_counts()\n",
    "max_count = max(df[\"Genre\"].value_counts())\n",
    "for genre in genres:\n",
    "    needed = max_count - counts[genre]\n",
    "    extras = extras.append(df[df[\"Genre\"]==genre].sample(n=needed,replace=True))\n",
    "df = extras\n",
    "counts    = df[\"Genre\"].value_counts()\n",
    "colors_list = [colors[genre] for genre in genres]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into data frames of the right type\n",
    "x_cols    = [\"Is_Exp\",\"Danceability\",\"Energy\",\"Key\",\"Loudness\",\"Mode\",\"Speechiness\",\"Acousticness\",\"Instrumentalness\",\"Liveness\",\"Valence\",\"Tempo\",\"Time_Signature\"]\n",
    "y_cols    = [\"Genre\"]\n",
    "meta_cols = [\"Id\",\"Popularity\",\"Name\",\"Artist\"]\n",
    "\n",
    "X,y,meta = df[x_cols],df[y_cols].iloc[:,0],df[meta_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data and fit run 2D PCA on it\n",
    "scaler   = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "pca = PCA(n_components=2)\n",
    "prin_comp = pca.fit_transform(scaled_X)\n",
    "prin_df   = pd.DataFrame(data=prin_comp, columns=[\"PC1\",\"PC2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X,y, test_size=.2, random_state=1234, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "           random_state=1234, refit=True, scoring=None, solver='lbfgs',\n",
      "           tol=0.0001, verbose=0)\n",
      "Training Accuracy: 0.7104693679576151\n",
      "Testing  Accuracy: 0.706057893166219\n",
      "['rnb' 'hiphop' 'country' 'classical' 'edm_dance' 'rock']\n",
      "[[263 115  90   1  51  39]\n",
      " [ 85 436   6   0  24   8]\n",
      " [ 40   5 395  14  20  84]\n",
      " [  2   1  17 529   7   3]\n",
      " [ 41  19  42  11 373  72]\n",
      " [ 27  10 100   1  50 370]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       0.95      0.95      0.95       559\n",
      "     country       0.61      0.71      0.65       558\n",
      "   edm_dance       0.71      0.67      0.69       558\n",
      "      hiphop       0.74      0.78      0.76       559\n",
      "         rnb       0.57      0.47      0.52       559\n",
      "        rock       0.64      0.66      0.65       558\n",
      "\n",
      "   micro avg       0.71      0.71      0.71      3351\n",
      "   macro avg       0.71      0.71      0.70      3351\n",
      "weighted avg       0.71      0.71      0.70      3351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=1234, multi_class=\"multinomial\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "joblib.dump(clf, \"logistic.pkl\")\n",
    "y_pred = clf.predict(X_test)\n",
    "training = clf.score(X_train, y_train)\n",
    "testing  = clf.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(genres)\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical\n",
      "(0.003946303957833425, 'Liveness')\n",
      "(-0.012320837939287883, 'Tempo')\n",
      "(-0.059209190800346395, 'Mode')\n",
      "(0.1386253682006998, 'Valence')\n",
      "(-0.15647763936258957, 'Key')\n",
      "(0.18093054703667974, 'Speechiness')\n",
      "(-0.20481272917398125, 'Time_Signature')\n",
      "(0.36922499165517536, 'Energy')\n",
      "(-0.4348551978606229, 'Is_Exp')\n",
      "(1.0825861517214295, 'Acousticness')\n",
      "(1.1158497141655224, 'Instrumentalness')\n",
      "(-1.452747866697919, 'Danceability')\n",
      "(-2.399882193829322, 'Loudness')\n",
      "country\n",
      "(0.07627944681588716, 'Liveness')\n",
      "(0.1003827640241546, 'Tempo')\n",
      "(0.11020855853054035, 'Key')\n",
      "(-0.16959172164308817, 'Time_Signature')\n",
      "(0.2121117239536969, 'Acousticness')\n",
      "(0.36076982294641957, 'Loudness')\n",
      "(-0.6509743152183395, 'Energy')\n",
      "(-0.6658538708981445, 'Danceability')\n",
      "(-0.6714826407924182, 'Instrumentalness')\n",
      "(0.6964723020336722, 'Mode')\n",
      "(0.9575799765631113, 'Valence')\n",
      "(-0.9677900936521278, 'Is_Exp')\n",
      "(-0.9810181266605161, 'Speechiness')\n",
      "edm_dance\n",
      "(0.03402132915186239, 'Time_Signature')\n",
      "(-0.08386011756773848, 'Speechiness')\n",
      "(-0.08454727524350161, 'Key')\n",
      "(0.11213608379251035, 'Liveness')\n",
      "(0.13216797858573526, 'Acousticness')\n",
      "(-0.1924860206439391, 'Mode')\n",
      "(0.2496114113761188, 'Tempo')\n",
      "(-0.4174720448104948, 'Is_Exp')\n",
      "(0.8040444196557014, 'Loudness')\n",
      "(0.941913159864401, 'Energy')\n",
      "(0.9499091188040081, 'Danceability')\n",
      "(-1.1025048700157178, 'Valence')\n",
      "(1.2075061216826262, 'Instrumentalness')\n",
      "hiphop\n",
      "(0.13325047563379877, 'Key')\n",
      "(-0.1545978514316124, 'Liveness')\n",
      "(-0.17124506006217372, 'Valence')\n",
      "(0.19896480127755914, 'Energy')\n",
      "(0.2007318477577659, 'Time_Signature')\n",
      "(0.2506261914795515, 'Loudness')\n",
      "(-0.3010770683252134, 'Acousticness')\n",
      "(-0.302020375300559, 'Mode')\n",
      "(-0.3172001556017471, 'Tempo')\n",
      "(1.1712043274651838, 'Is_Exp')\n",
      "(-1.2245818649967286, 'Instrumentalness')\n",
      "(1.2370057679254187, 'Speechiness')\n",
      "(1.926815725310299, 'Danceability')\n",
      "rnb\n",
      "(0.05032488461954622, 'Valence')\n",
      "(-0.06157085549306501, 'Key')\n",
      "(-0.08486611557581421, 'Liveness')\n",
      "(-0.1298014390038206, 'Tempo')\n",
      "(0.17411990824209914, 'Time_Signature')\n",
      "(-0.22634256599991803, 'Instrumentalness')\n",
      "(-0.26068550798961426, 'Mode')\n",
      "(-0.3415089731254585, 'Acousticness')\n",
      "(0.5198230831996274, 'Is_Exp')\n",
      "(0.5250532850725275, 'Speechiness')\n",
      "(0.563096955477187, 'Loudness')\n",
      "(0.7547900217933518, 'Danceability')\n",
      "(-1.0555640144616925, 'Energy')\n",
      "rock\n",
      "(-0.03446863433465845, 'Time_Signature')\n",
      "(0.04710213244119558, 'Liveness')\n",
      "(0.059136735934814895, 'Key')\n",
      "(0.1093282571445808, 'Tempo')\n",
      "(0.11792879270078507, 'Mode')\n",
      "(0.12721970069453617, 'Valence')\n",
      "(0.12908992565843594, 'Is_Exp')\n",
      "(0.1964353768828979, 'Energy')\n",
      "(-0.2009487640590826, 'Instrumentalness')\n",
      "(0.4213448042704684, 'Loudness')\n",
      "(-0.7842798128101888, 'Acousticness')\n",
      "(-0.8781113558063723, 'Speechiness')\n",
      "(-1.5129131283115913, 'Danceability')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf.classes_)):\n",
    "    print(clf.classes_[i])\n",
    "    todos      = [(clf.coef_[i][j],list(X)[j]) for j in range(len(list(X)))]\n",
    "    todos.sort(key=lambda x: abs(x[0]))\n",
    "    for i in range(len(todos)):\n",
    "        print(todos[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_classifier(X, y, t_clf, params) :\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameters of a Decision Tree classifier,\n",
    "    calculating the k-fold CV performance for each setting and metric,\n",
    "    then selects the hyperparameters that maximize the average performance for each metric.\n",
    "    \"\"\"\n",
    "    clf  = GridSearchCV(t_clf, params, cv=5,scoring= \"accuracy\")\n",
    "    \n",
    "    clf.fit(X,y)\n",
    "    return clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=17, p=1,\n",
      "           weights='distance')\n",
      "Training Accuracy: 1.0\n",
      "Testing  Accuracy: 0.9829901521933752\n",
      "[[559   0   0   0   0   0]\n",
      " [  0 559   0   0   0   0]\n",
      " [  4   0 546   0   0   8]\n",
      " [  1   1  17 530   4   6]\n",
      " [  4   1   3   0 542   8]\n",
      " [  0   0   0   0   0 558]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       1.00      0.95      0.97       559\n",
      "     country       0.96      0.98      0.97       558\n",
      "   edm_dance       0.99      0.97      0.98       558\n",
      "      hiphop       1.00      1.00      1.00       559\n",
      "         rnb       0.98      1.00      0.99       559\n",
      "        rock       0.96      1.00      0.98       558\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      3351\n",
      "   macro avg       0.98      0.98      0.98      3351\n",
      "weighted avg       0.98      0.98      0.98      3351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = [\"uniform\",\"distance\"]\n",
    "pvals   = [1,2]\n",
    "n_neigh = range(1,40,2)\n",
    "params  = {\n",
    "    \"p\": range(5,22,2),\n",
    "    \"weights\": weights,\n",
    "    \"p\": pvals,\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "clf = best_classifier(X_train,y_train,knn,params)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "joblib.dump(clf, \"knn.pkl\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "training = clf.score(X_train, y_train)\n",
    "testing  = clf.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=11,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Training Accuracy: 0.9055294381016342\n",
      "Testing  Accuracy: 0.8731721874067443\n",
      "[[491  36  17   0   2  13]\n",
      " [ 48 502   0   0   6   3]\n",
      " [ 39   7 462   1  12  37]\n",
      " [  5   1   7 533  11   2]\n",
      " [ 30  13  27   0 467  21]\n",
      " [ 34   2  39   0  12 471]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       1.00      0.95      0.98       559\n",
      "     country       0.84      0.83      0.83       558\n",
      "   edm_dance       0.92      0.84      0.87       558\n",
      "      hiphop       0.89      0.90      0.90       559\n",
      "         rnb       0.76      0.88      0.81       559\n",
      "        rock       0.86      0.84      0.85       558\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      3351\n",
      "   macro avg       0.88      0.87      0.87      3351\n",
      "weighted avg       0.88      0.87      0.87      3351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": range(5,12),\n",
    "    \"min_samples_leaf\": range(1,10),\n",
    "    \"criterion\": [\"gini\",\"entropy\"]\n",
    "}\n",
    "t = DecisionTreeClassifier()\n",
    "\n",
    "DTree = best_classifier(X_train, y_train, t, params)\n",
    "\n",
    "print(DTree)\n",
    "\n",
    "joblib.dump(DTree, \"dtree.pkl\")\n",
    "\n",
    "# predict genres of test data\n",
    "accuracy = DTree.score(X_test,y_test)\n",
    "y_pred = DTree.predict(X_test)\n",
    "training = DTree.score(X_train, y_train)\n",
    "testing  = DTree.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = DTree.feature_importances_\n",
    "d_feats      = list(X)\n",
    "todos      = [(importance[i],d_feats[i]) for i in range(len(d_feats))]\n",
    "todos.sort(key=lambda x: x[0],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.23236646555203988, 'Loudness'),\n",
       " (0.11972763774214497, 'Speechiness'),\n",
       " (0.11116756671594244, 'Danceability'),\n",
       " (0.10370262721781753, 'Instrumentalness'),\n",
       " (0.09066175301567177, 'Is_Exp'),\n",
       " (0.08960550874967296, 'Acousticness'),\n",
       " (0.0794520600186662, 'Energy'),\n",
       " (0.06269239212140733, 'Tempo'),\n",
       " (0.04421285160139217, 'Valence'),\n",
       " (0.03159769648938847, 'Liveness'),\n",
       " (0.0168126251574168, 'Key'),\n",
       " (0.014429366236905213, 'Mode'),\n",
       " (0.0035714493815342196, 'Time_Signature')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier accuracy is\n",
      "0.1683079677708147\n"
     ]
    }
   ],
   "source": [
    "# compare to stratified dummy classifier\n",
    "dummy = DummyClassifier(strategy='stratified')\n",
    "\n",
    "\n",
    "\n",
    "dummy.fit(X_train,y_train)\n",
    "\n",
    "joblib.dump(dummy, \"dummy.pkl\")\n",
    "dummy_accuracy = dummy.score(X_test,y_test)\n",
    "print( \"Dummy classifier accuracy is\" )\n",
    "print(dummy_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
