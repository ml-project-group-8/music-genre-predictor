{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports yay\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.multiclass import OneVsOneClassifier\n",
    "# Preprocessing and visualization\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Metric functions\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors    import KNeighborsClassifier\n",
    "from sklearn.dummy        import DummyClassifier\n",
    "from sklearn.tree         import DecisionTreeClassifier\n",
    "from sklearn.svm          import SVC\n",
    "# Model selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ignore warnings if they happen, we don't care (that much)\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "# Cross-validation takes a minute, so we will save these models\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "from lyric_features import genre_transform_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['come', 'day', 'don', 'good', 'got', 'just', 'know', 'let', 'life', 'like', 'little', 'll', 'love', 'make', 'man', 'said', 'say', 'scp', 'time', 'way', 'TTR', 'Avg_Wrdlen']\n"
     ]
    }
   ],
   "source": [
    "df     = pd.read_csv(\"data/lyrical_genius.csv\")\n",
    "\n",
    "# Remove pop songs, they are all over the place and hurt classification\n",
    "df = df[(df[\"Genre\"] != \"pop\")]\n",
    "\n",
    "# Remove some irrelevant columns\n",
    "df = df.drop(columns=\"Unnamed: 0\")\n",
    "df = df.drop(columns=\"Unnamed: 0.1\")\n",
    "\n",
    "# We go ahead and remove ALL duplicates\n",
    "df = df.drop_duplicates(subset=[\"Name\",\"Artist\"],keep=False)\n",
    "\n",
    "# Give each genre a new cool color\n",
    "genres = df[\"Genre\"].unique()\n",
    "unique_colors = [\n",
    "    '#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080'\n",
    "]\n",
    "colors = {}\n",
    "i = 0\n",
    "for genre in genres:\n",
    "    colors[genre] = unique_colors[i]\n",
    "    i+=1\n",
    "\n",
    "counts    = df[\"Genre\"].value_counts()\n",
    "colors_list = [colors[genre] for genre in genres]\n",
    "\n",
    "df, vectorizer = genre_transform_lyrics(df,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into data frames of the right type\n",
    "x_cols    = [\"Is_Exp\",\"Danceability\",\"Energy\",\"Key\",\"Loudness\",\"Mode\",\"Speechiness\",\"Acousticness\",\"Instrumentalness\",\"Liveness\",\"Valence\",\"Tempo\",\"Time_Signature\"]\n",
    "y_cols    = [\"Genre\"]\n",
    "meta_cols = [\"Id\",\"Popularity\",\"Name\",\"Artist\"]\n",
    "lyr_cols  = vectorizer.get_feature_names() + [\"TTR\",\"Avg_Wrdlen\"]\n",
    "\n",
    "X,y,meta = df[x_cols],df[y_cols].iloc[:,0],df[meta_cols]\n",
    "\n",
    "# Split \n",
    "X_trainP, X_testP, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=1234, stratify=y)\n",
    "\n",
    "extras    = pd.DataFrame()\n",
    "counts    = y_train.value_counts()\n",
    "min_count = min(counts)\n",
    "extra_y   = pd.Series()\n",
    "for genre in genres:\n",
    "    for i in range(min_count):\n",
    "        extra_y = extra_y.append(pd.Series([genre]))\n",
    "    extras = extras.append(X_trainP[y_train==genre].sample(n=min_count,replace=False))\n",
    "X_trainP = extras\n",
    "y_train = extra_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data and fit run 2D PCA on it\n",
    "scaler   = StandardScaler()\n",
    "scaler.fit(X_trainP)\n",
    "X_train = scaler.transform(X_trainP)\n",
    "X_test  = scaler.transform(X_testP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegressionCV(Cs=10, class_weight=None, cv=5, dual=False,\n",
      "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
      "           multi_class='multinomial', n_jobs=None, penalty='l2',\n",
      "           random_state=1234, refit=True, scoring=None, solver='lbfgs',\n",
      "           tol=0.0001, verbose=0)\n",
      "Training Accuracy: 0.7222222222222222\n",
      "Testing  Accuracy: 0.79185119574845\n",
      "['rnb' 'hiphop' 'country' 'classical' 'edm_dance' 'rock']\n",
      "[[ 33  16   9   0   4   3]\n",
      " [ 22  55   2   0   2   0]\n",
      " [ 21   0 121   3   2  33]\n",
      " [  1   1  18 526  10   3]\n",
      " [ 12   5  17   1 109  25]\n",
      " [  3   1  12   0   9  50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       0.99      0.94      0.97       559\n",
      "     country       0.68      0.67      0.67       180\n",
      "   edm_dance       0.80      0.64      0.71       169\n",
      "      hiphop       0.71      0.68      0.69        81\n",
      "         rnb       0.36      0.51      0.42        65\n",
      "        rock       0.44      0.67      0.53        75\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1129\n",
      "   macro avg       0.66      0.69      0.67      1129\n",
      "weighted avg       0.82      0.79      0.80      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=1234, multi_class=\"multinomial\")\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "joblib.dump(clf, \"logistic.pkl\")\n",
    "y_pred = clf.predict(X_test)\n",
    "training = clf.score(X_train, y_train)\n",
    "testing  = clf.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(genres)\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed = X_test[(y_test != y_pred)]\n",
    "ymiss  = y_test[(y_test != y_pred)]\n",
    "missP  = clf.predict_proba(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxclass = missP.argmax(axis=1)\n",
    "maxprob  = missP.max(axis=1)\n",
    "biggest  = maxprob.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnb\n",
      "0.9804370324830941\n",
      "['hiphop']\n"
     ]
    }
   ],
   "source": [
    "print(ymiss.iloc[biggest]) # Actual\n",
    "print(max(max(clf.predict_proba(missed[biggest].reshape(1,-1)))))\n",
    "print(clf.predict(missed[biggest].reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.0000e+00,  8.9800e-01,  6.7700e-01,  1.0000e+00, -6.9070e+00,\n",
       "        1.0000e+00,  3.6200e-01,  3.5400e-01,  4.8500e-06,  4.4900e-01,\n",
       "        8.6400e-01,  1.5502e+02,  4.0000e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(missed[biggest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classical\n",
      "(-0.1292597792276011, 'Mode')\n",
      "(0.1569180924906271, 'Liveness')\n",
      "(-0.1632586643070189, 'Tempo')\n",
      "(-0.228282223895718, 'Key')\n",
      "(-0.2591444374023151, 'Time_Signature')\n",
      "(0.35511967218871265, 'Speechiness')\n",
      "(0.3671887697575097, 'Energy')\n",
      "(0.43326013077154846, 'Valence')\n",
      "(0.5070590057541889, 'Is_Exp')\n",
      "(0.9804583302656056, 'Acousticness')\n",
      "(-1.3344857139520536, 'Danceability')\n",
      "(1.6207446105587562, 'Instrumentalness')\n",
      "(-2.7554639387709945, 'Loudness')\n",
      "country\n",
      "(0.007519767186701086, 'Time_Signature')\n",
      "(0.06614022691364303, 'Key')\n",
      "(0.07575409584085906, 'Tempo')\n",
      "(-0.08954636997179964, 'Liveness')\n",
      "(0.37974288917056204, 'Loudness')\n",
      "(0.41711207885547225, 'Acousticness')\n",
      "(-0.5286389808886242, 'Energy')\n",
      "(0.6192413193270783, 'Mode')\n",
      "(-0.7845020455388401, 'Danceability')\n",
      "(0.8960628543366024, 'Valence')\n",
      "(-1.0784620319160465, 'Instrumentalness')\n",
      "(-1.636603820182925, 'Speechiness')\n",
      "(-2.207858705649459, 'Is_Exp')\n",
      "edm_dance\n",
      "(0.0032269814895507275, 'Liveness')\n",
      "(-0.029499723700539143, 'Acousticness')\n",
      "(0.08467371463814224, 'Speechiness')\n",
      "(-0.12626518702660203, 'Mode')\n",
      "(-0.1323214685938778, 'Key')\n",
      "(0.1800031633746324, 'Time_Signature')\n",
      "(0.43047265674570845, 'Tempo')\n",
      "(-0.5896806272925531, 'Is_Exp')\n",
      "(0.6777054382944545, 'Energy')\n",
      "(0.768924039701247, 'Danceability')\n",
      "(-0.9999015646995535, 'Valence')\n",
      "(1.048301771486231, 'Loudness')\n",
      "(1.6643785026814304, 'Instrumentalness')\n",
      "hiphop\n",
      "(0.005241059802071577, 'Time_Signature')\n",
      "(0.020435144973478096, 'Liveness')\n",
      "(0.18348150323333196, 'Loudness')\n",
      "(0.20353630633439898, 'Key')\n",
      "(-0.2682557498043844, 'Acousticness')\n",
      "(0.26865131722134217, 'Energy')\n",
      "(-0.29203805772466734, 'Mode')\n",
      "(-0.3199144485330973, 'Tempo')\n",
      "(-0.372728602228525, 'Valence')\n",
      "(1.4306535787428283, 'Is_Exp')\n",
      "(1.494254287000317, 'Speechiness')\n",
      "(2.240224312862894, 'Danceability')\n",
      "(-2.5326476568096843, 'Instrumentalness')\n",
      "rnb\n",
      "(-0.037086396886640643, 'Valence')\n",
      "(0.05298471744276328, 'Key')\n",
      "(0.10843634351408299, 'Time_Signature')\n",
      "(-0.13257777502254348, 'Liveness')\n",
      "(-0.1677463028283771, 'Mode')\n",
      "(-0.20597656562094585, 'Tempo')\n",
      "(0.24027371921054863, 'Instrumentalness')\n",
      "(-0.4078265487455066, 'Acousticness')\n",
      "(0.6356068893530109, 'Speechiness')\n",
      "(0.640068958607431, 'Danceability')\n",
      "(0.7019214628513979, 'Is_Exp')\n",
      "(0.8239178309487311, 'Loudness')\n",
      "(-1.2445435401707305, 'Energy')\n",
      "rock\n",
      "(0.03794244179880243, 'Key')\n",
      "(0.041543926040666646, 'Liveness')\n",
      "(-0.042055896475196655, 'Time_Signature')\n",
      "(0.08039357870650544, 'Valence')\n",
      "(0.08571285627488609, 'Instrumentalness')\n",
      "(0.09606800748016447, 'Mode')\n",
      "(0.15790528559351688, 'Is_Exp')\n",
      "(0.18292292587451678, 'Tempo')\n",
      "(0.3200199439321696, 'Loudness')\n",
      "(0.4596369957860445, 'Energy')\n",
      "(-0.6919883868706065, 'Acousticness')\n",
      "(-0.9330507429972182, 'Speechiness')\n",
      "(-1.5302295516807292, 'Danceability')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clf.classes_)):\n",
    "    print(clf.classes_[i])\n",
    "    todos      = [(clf.coef_[i][j],list(X)[j]) for j in range(len(list(X)))]\n",
    "    todos.sort(key=lambda x: abs(x[0]))\n",
    "    for i in range(len(todos)):\n",
    "        print(todos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_classifier(X, y, t_clf, params,scores=[\"accuracy\"]) :\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameters of a Decision Tree classifier,\n",
    "    calculating the k-fold CV performance for each setting and metric,\n",
    "    then selects the hyperparameters that maximize the average performance for each metric.\n",
    "    \"\"\"\n",
    "    best_parms = []\n",
    "    \n",
    "    for score in scores:\n",
    "        base_clf = clone(t_clf)\n",
    "        print(\"Scoring for {}\".format(score))\n",
    "        clf   = GridSearchCV(base_clf, params, cv=5,scoring=score)\n",
    "        \n",
    "        clf.fit(X,y)\n",
    "        print(\"Done fitting\")\n",
    "        \n",
    "        mts   = clf.cv_results_[\"mean_test_score\"]\n",
    "        parms = clf.cv_results_[\"params\"]\n",
    "        \n",
    "        for mt, parm in zip(mts,parms):\n",
    "            print(\"Score: {:.4f}; Parameters {}\".format(mt, parm))\n",
    "        \n",
    "        best_parms.append(clf.best_estimator_)\n",
    "    return best_parms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring for precision\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-51a95286349d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m }\n\u001b[1;32m      5\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-d46ec8a98ef1>\u001b[0m in \u001b[0;36mbest_classifier\u001b[0;34m(X, y, t_clf, params, scores)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mclf\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done fitting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \"\"\"\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[0;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m---> 98\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m   1270\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0;32m-> 1047\u001b[0;31m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "weights = [\"uniform\"]\n",
    "params  = {\n",
    "    \"n_neighbors\": range(5,22,2)\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "clf = best_classifier(X_train,y_train,knn,params,scores=[\"precision\"])\n",
    "\n",
    "print(clf)\n",
    "# clf = KNeighborsClassifier(n_neighbors=1)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf, \"knn.pkl\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "training = clf.score(X_train, y_train)\n",
    "testing  = clf.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=9,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=4, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Training Accuracy: 0.8301404853128991\n",
      "Testing  Accuracy: 0.7723649247121346\n",
      "[[ 41  12   7   0   1   4]\n",
      " [ 20  52   3   0   3   3]\n",
      " [ 32   2 115   4   9  18]\n",
      " [  9   1  16 520  11   2]\n",
      " [ 22   3  20   1 103  20]\n",
      " [ 13   1  12   0   8  41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       0.99      0.93      0.96       559\n",
      "     country       0.66      0.64      0.65       180\n",
      "   edm_dance       0.76      0.61      0.68       169\n",
      "      hiphop       0.73      0.64      0.68        81\n",
      "         rnb       0.30      0.63      0.41        65\n",
      "        rock       0.47      0.55      0.50        75\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1129\n",
      "   macro avg       0.65      0.67      0.65      1129\n",
      "weighted avg       0.81      0.77      0.79      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"max_depth\": range(5,12),\n",
    "    \"min_samples_leaf\": range(1,10),\n",
    "    \"criterion\": [\"entropy\",\"gini\"]\n",
    "}\n",
    "t = DecisionTreeClassifier()\n",
    "\n",
    "# DTree = best_classifier(X_train, y_train, t, params, scores=[\"accuracy\"])[0]\n",
    "\n",
    "\n",
    "DTree = DecisionTreeClassifier(max_depth=9, min_samples_leaf=4, criterion=\"gini\")\n",
    "DTree.fit(X_train, y_train)\n",
    "print(DTree)\n",
    "joblib.dump(DTree, \"dtree.pkl\")\n",
    "\n",
    "# predict genres of test data\n",
    "accuracy = DTree.score(X_test,y_test)\n",
    "y_pred = DTree.predict(X_test)\n",
    "training = DTree.score(X_train, y_train)\n",
    "testing  = DTree.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = DTree.feature_importances_\n",
    "d_feats      = list(X)\n",
    "todos      = [(importance[i],d_feats[i]) for i in range(len(d_feats))]\n",
    "todos.sort(key=lambda x: x[0],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.24007244091331523, 'Loudness'),\n",
       " (0.12070987254439697, 'Speechiness'),\n",
       " (0.11802700079494063, 'Is_Exp'),\n",
       " (0.11786475507745937, 'Instrumentalness'),\n",
       " (0.10408651487809598, 'Acousticness'),\n",
       " (0.10218358944653987, 'Danceability'),\n",
       " (0.05606085475103492, 'Energy'),\n",
       " (0.04289684854243885, 'Valence'),\n",
       " (0.042797817418351876, 'Tempo'),\n",
       " (0.023937645622222975, 'Liveness'),\n",
       " (0.018854671429500952, 'Mode'),\n",
       " (0.012507988581702458, 'Key'),\n",
       " (0.0, 'Time_Signature')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for x in todos:\n",
    "    total += x[0]\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(todos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier accuracy is\n",
      "0.16031886625332153\n"
     ]
    }
   ],
   "source": [
    "# compare to stratified dummy classifier\n",
    "dummy = DummyClassifier(strategy='stratified')\n",
    "\n",
    "\n",
    "dummy.fit(X_train,y_train)\n",
    "\n",
    "joblib.dump(dummy, \"dummy.pkl\")\n",
    "dummy_accuracy = dummy.score(X_test,y_test)\n",
    "print( \"Dummy classifier accuracy is\" )\n",
    "print(dummy_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_features(coef, names, filename=\"\", top=-1):\n",
    "    imp = coef\n",
    "    imp, names = zip(*sorted(list(zip(imp, names))))\n",
    "\n",
    "    # Show all features\n",
    "    if top == -1:\n",
    "        top = len(names)\n",
    "\n",
    "    plt.barh(range(top), imp[::-1][0:top], align='center')\n",
    "    plt.yticks(range(top), names[::-1][0:top])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring for accuracy\n",
      "Done fitting\n",
      "Score: 0.6335; Parameters {'C': 0.001}\n",
      "Score: 0.6705; Parameters {'C': 0.01}\n",
      "Score: 0.7075; Parameters {'C': 0.1}\n",
      "Score: 0.7101; Parameters {'C': 1.0}\n",
      "Score: 0.7069; Parameters {'C': 10.0}\n",
      "Score: 0.7050; Parameters {'C': 100.0}\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "Training Accuracy: 0.7298850574712644\n",
      "Testing  Accuracy: 0.804251550044287\n",
      "[[ 34  16   8   0   4   3]\n",
      " [ 18  58   2   0   3   0]\n",
      " [ 16   0 131   4   2  27]\n",
      " [  1   1  19 526  10   2]\n",
      " [ 15   4  19   1 110  20]\n",
      " [  4   1  10   1  10  49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       0.99      0.94      0.96       559\n",
      "     country       0.69      0.73      0.71       180\n",
      "   edm_dance       0.79      0.65      0.71       169\n",
      "      hiphop       0.72      0.72      0.72        81\n",
      "         rnb       0.39      0.52      0.44        65\n",
      "        rock       0.49      0.65      0.56        75\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1129\n",
      "   macro avg       0.68      0.70      0.69      1129\n",
      "weighted avg       0.82      0.80      0.81      1129\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "params  = {\n",
    "    \"C\": 10.0 ** np.arange(-3, 3)\n",
    "}\n",
    "lin_svm = SVC(kernel=\"linear\", probability=True)\n",
    "clf = best_classifier(X_train,y_train,lin_svm,params)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "joblib.dump(clf, \"lin_svm.pkl\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "training = clf.score(X_train, y_train)\n",
    "testing  = clf.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "graph_features(abs(clf.coef_[0]), x_cols, filename=\"linsvmfeats.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring for accuracy\n",
      "Done fitting\n",
      "Score: 0.6335; Parameters {'C': 0.001, 'gamma': 5.5621024596506654e-12, 'probability': True}\n",
      "Score: 0.6335; Parameters {'C': 0.001, 'gamma': 5.5621024596506654e-12, 'probability': False}\n",
      "Score: 0.6098; Parameters {'C': 0.001, 'gamma': 3.139250628226836e-08, 'probability': True}\n",
      "Score: 0.6098; Parameters {'C': 0.001, 'gamma': 3.139250628226836e-08, 'probability': False}\n",
      "Score: 0.6117; Parameters {'C': 0.001, 'gamma': 0.00017717930545712261, 'probability': True}\n",
      "Score: 0.6117; Parameters {'C': 0.001, 'gamma': 0.00017717930545712261, 'probability': False}\n",
      "Score: 0.3748; Parameters {'C': 0.001, 'gamma': 1.0, 'probability': True}\n",
      "Score: 0.3748; Parameters {'C': 0.001, 'gamma': 1.0, 'probability': False}\n",
      "Score: 0.1679; Parameters {'C': 0.001, 'gamma': 5644.0, 'probability': True}\n",
      "Score: 0.1679; Parameters {'C': 0.001, 'gamma': 5644.0, 'probability': False}\n",
      "Score: 0.6335; Parameters {'C': 0.01, 'gamma': 5.5621024596506654e-12, 'probability': True}\n",
      "Score: 0.6335; Parameters {'C': 0.01, 'gamma': 5.5621024596506654e-12, 'probability': False}\n",
      "Score: 0.6098; Parameters {'C': 0.01, 'gamma': 3.139250628226836e-08, 'probability': True}\n",
      "Score: 0.6098; Parameters {'C': 0.01, 'gamma': 3.139250628226836e-08, 'probability': False}\n",
      "Score: 0.6117; Parameters {'C': 0.01, 'gamma': 0.00017717930545712261, 'probability': True}\n",
      "Score: 0.6117; Parameters {'C': 0.01, 'gamma': 0.00017717930545712261, 'probability': False}\n",
      "Score: 0.3748; Parameters {'C': 0.01, 'gamma': 1.0, 'probability': True}\n",
      "Score: 0.3748; Parameters {'C': 0.01, 'gamma': 1.0, 'probability': False}\n",
      "Score: 0.1679; Parameters {'C': 0.01, 'gamma': 5644.0, 'probability': True}\n",
      "Score: 0.1679; Parameters {'C': 0.01, 'gamma': 5644.0, 'probability': False}\n",
      "Score: 0.6335; Parameters {'C': 0.1, 'gamma': 5.5621024596506654e-12, 'probability': True}\n",
      "Score: 0.6335; Parameters {'C': 0.1, 'gamma': 5.5621024596506654e-12, 'probability': False}\n",
      "Score: 0.6098; Parameters {'C': 0.1, 'gamma': 3.139250628226836e-08, 'probability': True}\n",
      "Score: 0.6098; Parameters {'C': 0.1, 'gamma': 3.139250628226836e-08, 'probability': False}\n",
      "Score: 0.6117; Parameters {'C': 0.1, 'gamma': 0.00017717930545712261, 'probability': True}\n",
      "Score: 0.6117; Parameters {'C': 0.1, 'gamma': 0.00017717930545712261, 'probability': False}\n",
      "Score: 0.3748; Parameters {'C': 0.1, 'gamma': 1.0, 'probability': True}\n",
      "Score: 0.3748; Parameters {'C': 0.1, 'gamma': 1.0, 'probability': False}\n",
      "Score: 0.1679; Parameters {'C': 0.1, 'gamma': 5644.0, 'probability': True}\n",
      "Score: 0.1679; Parameters {'C': 0.1, 'gamma': 5644.0, 'probability': False}\n",
      "Score: 0.6335; Parameters {'C': 1.0, 'gamma': 5.5621024596506654e-12, 'probability': True}\n",
      "Score: 0.6335; Parameters {'C': 1.0, 'gamma': 5.5621024596506654e-12, 'probability': False}\n",
      "Score: 0.6098; Parameters {'C': 1.0, 'gamma': 3.139250628226836e-08, 'probability': True}\n",
      "Score: 0.6098; Parameters {'C': 1.0, 'gamma': 3.139250628226836e-08, 'probability': False}\n",
      "Score: 0.6111; Parameters {'C': 1.0, 'gamma': 0.00017717930545712261, 'probability': True}\n",
      "Score: 0.6111; Parameters {'C': 1.0, 'gamma': 0.00017717930545712261, 'probability': False}\n",
      "Score: 0.5932; Parameters {'C': 1.0, 'gamma': 1.0, 'probability': True}\n",
      "Score: 0.5932; Parameters {'C': 1.0, 'gamma': 1.0, 'probability': False}\n",
      "Score: 0.1679; Parameters {'C': 1.0, 'gamma': 5644.0, 'probability': True}\n",
      "Score: 0.1679; Parameters {'C': 1.0, 'gamma': 5644.0, 'probability': False}\n",
      "Score: 0.6335; Parameters {'C': 10.0, 'gamma': 5.5621024596506654e-12, 'probability': True}\n",
      "Score: 0.6335; Parameters {'C': 10.0, 'gamma': 5.5621024596506654e-12, 'probability': False}\n",
      "Score: 0.6098; Parameters {'C': 10.0, 'gamma': 3.139250628226836e-08, 'probability': True}\n",
      "Score: 0.6098; Parameters {'C': 10.0, 'gamma': 3.139250628226836e-08, 'probability': False}\n",
      "Score: 0.6501; Parameters {'C': 10.0, 'gamma': 0.00017717930545712261, 'probability': True}\n",
      "Score: 0.6501; Parameters {'C': 10.0, 'gamma': 0.00017717930545712261, 'probability': False}\n",
      "Score: 0.5913; Parameters {'C': 10.0, 'gamma': 1.0, 'probability': True}\n",
      "Score: 0.5913; Parameters {'C': 10.0, 'gamma': 1.0, 'probability': False}\n",
      "Score: 0.1679; Parameters {'C': 10.0, 'gamma': 5644.0, 'probability': True}\n",
      "Score: 0.1679; Parameters {'C': 10.0, 'gamma': 5644.0, 'probability': False}\n",
      "Score: 0.6335; Parameters {'C': 100.0, 'gamma': 5.5621024596506654e-12, 'probability': True}\n",
      "Score: 0.6335; Parameters {'C': 100.0, 'gamma': 5.5621024596506654e-12, 'probability': False}\n",
      "Score: 0.6098; Parameters {'C': 100.0, 'gamma': 3.139250628226836e-08, 'probability': True}\n",
      "Score: 0.6098; Parameters {'C': 100.0, 'gamma': 3.139250628226836e-08, 'probability': False}\n",
      "Score: 0.6999; Parameters {'C': 100.0, 'gamma': 0.00017717930545712261, 'probability': True}\n",
      "Score: 0.6999; Parameters {'C': 100.0, 'gamma': 0.00017717930545712261, 'probability': False}\n",
      "Score: 0.5913; Parameters {'C': 100.0, 'gamma': 1.0, 'probability': True}\n",
      "Score: 0.5913; Parameters {'C': 100.0, 'gamma': 1.0, 'probability': False}\n",
      "Score: 0.1679; Parameters {'C': 100.0, 'gamma': 5644.0, 'probability': True}\n",
      "Score: 0.1679; Parameters {'C': 100.0, 'gamma': 5644.0, 'probability': False}\n",
      "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.00017717930545712261,\n",
      "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "Training Accuracy: 0.722860791826309\n",
      "Testing  Accuracy: 0.7945084145261293\n",
      "[[ 33  16   9   0   4   3]\n",
      " [ 17  59   2   0   3   0]\n",
      " [ 15   0 125   3   1  36]\n",
      " [  1   1  20 527   7   3]\n",
      " [ 16   5  19   1  99  29]\n",
      " [  5   1  12   0   3  54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   classical       0.99      0.94      0.97       559\n",
      "     country       0.67      0.69      0.68       180\n",
      "   edm_dance       0.85      0.59      0.69       169\n",
      "      hiphop       0.72      0.73      0.72        81\n",
      "         rnb       0.38      0.51      0.43        65\n",
      "        rock       0.43      0.72      0.54        75\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1129\n",
      "   macro avg       0.67      0.70      0.67      1129\n",
      "weighted avg       0.83      0.79      0.80      1129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params  = {\n",
    "    \"C\": 10.0 ** np.arange(-3, 3),\n",
    "    \"gamma\": float(X.shape[0]) ** np.arange(-3, 2),\n",
    "    \"probability\": [True,False]\n",
    "}\n",
    "rbf_svm = SVC(kernel=\"rbf\")\n",
    "clf = best_classifier(X_train,y_train,rbf_svm,params)\n",
    "\n",
    "print(clf)\n",
    "\n",
    "joblib.dump(clf, \"rbf_svm.pkl\")\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "training = clf.score(X_train, y_train)\n",
    "testing  = clf.score(X_test,  y_test)\n",
    "print(\"Training Accuracy: {}\".format(training))\n",
    "print(\"Testing  Accuracy: {}\".format(testing))\n",
    "print(confusion_matrix(y_test,y_pred,labels=genres))\n",
    "print(classification_report(y_test, y_pred)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
